{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesNames = [x for x in os.listdir(path) if \".mat\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S1.mat',\n",
       " 'S3.mat',\n",
       " 'S2.mat',\n",
       " 'S6.mat',\n",
       " 'S7.mat',\n",
       " 'S5.mat',\n",
       " 'S4.mat',\n",
       " 'S8.mat']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDictionay = {10:\"start Block Event\",\n",
    "                 1 : \"Rest Cue\",\n",
    "                 3: \"Right Arm\",\n",
    "                 4: \"Left Arm\",\n",
    "                 7: \"Right Hand\",\n",
    "                 8: \"Left Hand\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y = getAllData(filesNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([X_train.shape[0],1,500,21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5867, 1, 500, 21)\n",
      "(5867, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 21), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        #self.fc1 = nn.Linear(248 * batch_size, 6)\n",
    "        self.fc1 = nn.Linear(248, 6)\n",
    "        self.softmax = nn.Softmax(dim = 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        #x = x.view(-1, 248 * batch_size)\n",
    "        x = x.view(-1, self.numFeatures(x) ,248)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        \n",
    "        #return self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    def numFeatures(self, x):\n",
    "        return int(np.array(x.shape).prod() / 248)\n",
    "\n",
    "\n",
    "#net = EEGNet().cuda(0)\n",
    "net = EEGNet()\n",
    "#print (net.forward(Variable(torch.Tensor(np.random.rand(1, 1, 120, 64)).cuda(0))))\n",
    "criterion = nn.BCELoss(size_average = True)\n",
    "optimizer = optim.Adam(net.parameters(), lr= 0.001, weight_decay=0)\n",
    "\n",
    "#Source: https://github.com/aliasvishnu/EEGNet/blob/master/EEGNet-PyTorch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EEGNet(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(1, 21), stride=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(16, eps=False, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (padding1): ZeroPad2d(padding=(16, 17, 0, 1), value=0)\n",
       "  (conv2): Conv2d(1, 4, kernel_size=(2, 32), stride=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(4, eps=False, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pooling2): MaxPool2d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (padding2): ZeroPad2d(padding=(2, 1, 4, 3), value=0)\n",
       "  (conv3): Conv2d(4, 4, kernel_size=(8, 4), stride=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(4, eps=False, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pooling3): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=248, out_features=6, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "    results = []\n",
    "    batch_size = 64\n",
    "    \n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(int(len(X)/batch_size)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        #inputs = Variable(torch.from_numpy(X[s:e]).cuda(0))\n",
    "        inputs = Variable(torch.from_numpy(X[s:e]))\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    #inputs = Variable(torch.from_numpy(X).cuda(0))\n",
    "    inputs = Variable(torch.from_numpy(X))\n",
    "    predicted = model(inputs)\n",
    "    \n",
    "    predicted = predicted.data.cpu().numpy()\n",
    "    predicted = predicted[0]\n",
    "    Y = Y.argmax(axis = 1)\n",
    "    predicted = predicted.argmax(axis = 1)\n",
    "    \n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(sum(Y == predicted) / Y.shape[0])\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted))\n",
    "        if param == \"recall\":\n",
    "            results.append(recall_score(Y, np.round(predicted)))\n",
    "        if param == \"precision\":\n",
    "            results.append(precision_score(Y, np.round(predicted)))\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(Y, np.round(predicted))\n",
    "            recall = recall_score(Y, np.round(predicted))\n",
    "            results.append(2*precision*recall/ (precision+recall))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Partitions\n",
    "X_train = X_train[0:200]\n",
    "y_train = Y[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr= 1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc']\n",
      "Training Loss  tensor(0.4201)\n",
      "Train -  [0.575]\n",
      "\n",
      "Epoch  1\n",
      "['acc']\n",
      "Training Loss  tensor(0.4194)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  2\n",
      "['acc']\n",
      "Training Loss  tensor(0.4186)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  3\n",
      "['acc']\n",
      "Training Loss  tensor(0.4179)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  4\n",
      "['acc']\n",
      "Training Loss  tensor(0.4171)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  5\n",
      "['acc']\n",
      "Training Loss  tensor(0.4163)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  6\n",
      "['acc']\n",
      "Training Loss  tensor(0.4156)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  7\n",
      "['acc']\n",
      "Training Loss  tensor(0.4148)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  8\n",
      "['acc']\n",
      "Training Loss  tensor(0.4141)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  9\n",
      "['acc']\n",
      "Training Loss  tensor(0.4133)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  10\n",
      "['acc']\n",
      "Training Loss  tensor(0.4126)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  11\n",
      "['acc']\n",
      "Training Loss  tensor(0.4118)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  12\n",
      "['acc']\n",
      "Training Loss  tensor(0.4110)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  13\n",
      "['acc']\n",
      "Training Loss  tensor(0.4103)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  14\n",
      "['acc']\n",
      "Training Loss  tensor(0.4095)\n",
      "Train -  [0.58]\n",
      "\n",
      "Epoch  15\n",
      "['acc']\n",
      "Training Loss  tensor(0.4088)\n",
      "Train -  [0.575]\n",
      "\n",
      "Epoch  16\n",
      "['acc']\n",
      "Training Loss  tensor(0.4080)\n",
      "Train -  [0.575]\n",
      "\n",
      "Epoch  17\n",
      "['acc']\n",
      "Training Loss  tensor(0.4073)\n",
      "Train -  [0.575]\n",
      "\n",
      "Epoch  18\n",
      "['acc']\n",
      "Training Loss  tensor(0.4065)\n",
      "Train -  [0.575]\n",
      "\n",
      "Epoch  19\n",
      "['acc']\n",
      "Training Loss  tensor(0.4058)\n",
      "Train -  [0.575]\n",
      "\n",
      "Epoch  20\n",
      "['acc']\n",
      "Training Loss  tensor(0.4050)\n",
      "Train -  [0.575]\n",
      "\n",
      "Epoch  21\n",
      "['acc']\n",
      "Training Loss  tensor(0.4043)\n",
      "Train -  [0.585]\n",
      "\n",
      "Epoch  22\n",
      "['acc']\n",
      "Training Loss  tensor(0.4035)\n",
      "Train -  [0.585]\n",
      "\n",
      "Epoch  23\n",
      "['acc']\n",
      "Training Loss  tensor(0.4028)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  24\n",
      "['acc']\n",
      "Training Loss  tensor(0.4020)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  25\n",
      "['acc']\n",
      "Training Loss  tensor(0.4013)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  26\n",
      "['acc']\n",
      "Training Loss  tensor(0.4006)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  27\n",
      "['acc']\n",
      "Training Loss  tensor(0.3998)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  28\n",
      "['acc']\n",
      "Training Loss  tensor(0.3991)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  29\n",
      "['acc']\n",
      "Training Loss  tensor(0.3983)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  30\n",
      "['acc']\n",
      "Training Loss  tensor(0.3976)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  31\n",
      "['acc']\n",
      "Training Loss  tensor(0.3969)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  32\n",
      "['acc']\n",
      "Training Loss  tensor(0.3961)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  33\n",
      "['acc']\n",
      "Training Loss  tensor(0.3954)\n",
      "Train -  [0.59]\n",
      "\n",
      "Epoch  34\n",
      "['acc']\n",
      "Training Loss  tensor(0.3947)\n",
      "Train -  [0.595]\n",
      "\n",
      "Epoch  35\n",
      "['acc']\n",
      "Training Loss  tensor(0.3939)\n",
      "Train -  [0.6]\n",
      "\n",
      "Epoch  36\n",
      "['acc']\n",
      "Training Loss  tensor(0.3932)\n",
      "Train -  [0.6]\n",
      "\n",
      "Epoch  37\n",
      "['acc']\n",
      "Training Loss  tensor(0.3924)\n",
      "Train -  [0.6]\n",
      "\n",
      "Epoch  38\n",
      "['acc']\n",
      "Training Loss  tensor(0.3917)\n",
      "Train -  [0.6]\n",
      "\n",
      "Epoch  39\n",
      "['acc']\n",
      "Training Loss  tensor(0.3910)\n",
      "Train -  [0.6]\n",
      "\n",
      "Epoch  40\n",
      "['acc']\n",
      "Training Loss  tensor(0.3902)\n",
      "Train -  [0.605]\n",
      "\n",
      "Epoch  41\n",
      "['acc']\n",
      "Training Loss  tensor(0.3895)\n",
      "Train -  [0.605]\n",
      "\n",
      "Epoch  42\n",
      "['acc']\n",
      "Training Loss  tensor(0.3888)\n",
      "Train -  [0.605]\n",
      "\n",
      "Epoch  43\n",
      "['acc']\n",
      "Training Loss  tensor(0.3880)\n",
      "Train -  [0.605]\n",
      "\n",
      "Epoch  44\n",
      "['acc']\n",
      "Training Loss  tensor(0.3873)\n",
      "Train -  [0.605]\n",
      "\n",
      "Epoch  45\n",
      "['acc']\n",
      "Training Loss  tensor(0.3866)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  46\n",
      "['acc']\n",
      "Training Loss  tensor(0.3859)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  47\n",
      "['acc']\n",
      "Training Loss  tensor(0.3851)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  48\n",
      "['acc']\n",
      "Training Loss  tensor(0.3844)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  49\n",
      "['acc']\n",
      "Training Loss  tensor(0.3837)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  50\n",
      "['acc']\n",
      "Training Loss  tensor(0.3830)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  51\n",
      "['acc']\n",
      "Training Loss  tensor(0.3822)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  52\n",
      "['acc']\n",
      "Training Loss  tensor(0.3815)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  53\n",
      "['acc']\n",
      "Training Loss  tensor(0.3808)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  54\n",
      "['acc']\n",
      "Training Loss  tensor(0.3801)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  55\n",
      "['acc']\n",
      "Training Loss  tensor(0.3794)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  56\n",
      "['acc']\n",
      "Training Loss  tensor(0.3786)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  57\n",
      "['acc']\n",
      "Training Loss  tensor(0.3779)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  58\n",
      "['acc']\n",
      "Training Loss  tensor(0.3772)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  59\n",
      "['acc']\n",
      "Training Loss  tensor(0.3765)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  60\n",
      "['acc']\n",
      "Training Loss  tensor(0.3758)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  61\n",
      "['acc']\n",
      "Training Loss  tensor(0.3750)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  62\n",
      "['acc']\n",
      "Training Loss  tensor(0.3743)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  63\n",
      "['acc']\n",
      "Training Loss  tensor(0.3736)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  64\n",
      "['acc']\n",
      "Training Loss  tensor(0.3729)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  65\n",
      "['acc']\n",
      "Training Loss  tensor(0.3722)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  66\n",
      "['acc']\n",
      "Training Loss  tensor(0.3714)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  67\n",
      "['acc']\n",
      "Training Loss  tensor(0.3707)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  68\n",
      "['acc']\n",
      "Training Loss  tensor(0.3700)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  69\n",
      "['acc']\n",
      "Training Loss  tensor(0.3693)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  70\n",
      "['acc']\n",
      "Training Loss  tensor(0.3686)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  71\n",
      "['acc']\n",
      "Training Loss  tensor(0.3679)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  72\n",
      "['acc']\n",
      "Training Loss  tensor(0.3672)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  73\n",
      "['acc']\n",
      "Training Loss  tensor(0.3664)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  74\n",
      "['acc']\n",
      "Training Loss  tensor(0.3657)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  75\n",
      "['acc']\n",
      "Training Loss  tensor(0.3650)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  76\n",
      "['acc']\n",
      "Training Loss  tensor(0.3643)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  77\n",
      "['acc']\n",
      "Training Loss  tensor(0.3636)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  78\n",
      "['acc']\n",
      "Training Loss  tensor(0.3629)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  79\n",
      "['acc']\n",
      "Training Loss  tensor(0.3622)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  80\n",
      "['acc']\n",
      "Training Loss  tensor(0.3615)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  81\n",
      "['acc']\n",
      "Training Loss  tensor(0.3607)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  82\n",
      "['acc']\n",
      "Training Loss  tensor(0.3600)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  83\n",
      "['acc']\n",
      "Training Loss  tensor(0.3593)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  84\n",
      "['acc']\n",
      "Training Loss  tensor(0.3586)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  85\n",
      "['acc']\n",
      "Training Loss  tensor(0.3579)\n",
      "Train -  [0.61]\n",
      "\n",
      "Epoch  86\n",
      "['acc']\n",
      "Training Loss  tensor(0.3572)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  87\n",
      "['acc']\n",
      "Training Loss  tensor(0.3565)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  88\n",
      "['acc']\n",
      "Training Loss  tensor(0.3558)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  89\n",
      "['acc']\n",
      "Training Loss  tensor(0.3551)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  90\n",
      "['acc']\n",
      "Training Loss  tensor(0.3543)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  91\n",
      "['acc']\n",
      "Training Loss  tensor(0.3536)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  92\n",
      "['acc']\n",
      "Training Loss  tensor(0.3529)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  93\n",
      "['acc']\n",
      "Training Loss  tensor(0.3522)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  94\n",
      "['acc']\n",
      "Training Loss  tensor(0.3515)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  95\n",
      "['acc']\n",
      "Training Loss  tensor(0.3508)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  96\n",
      "['acc']\n",
      "Training Loss  tensor(0.3501)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  97\n",
      "['acc']\n",
      "Training Loss  tensor(0.3494)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  98\n",
      "['acc']\n",
      "Training Loss  tensor(0.3487)\n",
      "Train -  [0.615]\n",
      "\n",
      "Epoch  99\n",
      "['acc']\n",
      "Training Loss  tensor(0.3480)\n",
      "Train -  [0.615]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "trainingLoss = []\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    print (\"\\nEpoch \", epoch)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train)/batch_size-1)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X_train[s:e])\n",
    "        labels = torch.FloatTensor(np.array([y_train[s:e]])*1.0)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        #inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "    \n",
    "    # Validation accuracy\n",
    "    params = [\"acc\"]\n",
    "    trainingLoss.append(running_loss)\n",
    "    print (params)\n",
    "    print (\"Training Loss \", running_loss)\n",
    "    print (\"Train - \", evaluate(net, X_train, y_train, params))\n",
    "    #print (\"Validation - \", evaluate(net, X_val, y_val, params))\n",
    "    #print (\"Test - \", evaluate(net, X_test, y_test, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-9b8eec1fd974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
